{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMg9swCewFFPVcrs0aa7lqW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ap5967ap/Coursera-DeepLearning.AI-Stanford-University-Machine-Learning-Specialization/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "535enlBoMgO3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, Dense, Flatten, Dropout, LayerNormalization\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbedding(Layer):\n",
        "    def __init__(self, patch_size, embed_dim):\n",
        "        super(PatchEmbedding, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.projection = Dense(embed_dim)\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding='VALID'\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        embeddings = self.projection(patches)\n",
        "        return embeddings\n"
      ],
      "metadata": {
        "id": "j0Fa289OQluL"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(Layer):\n",
        "    def __init__(self, num_patches, embed_dim):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.pos_encoding = self.positional_encoding(num_patches, embed_dim)\n",
        "\n",
        "    def positional_encoding(self, num_patches, embed_dim):\n",
        "        # Create a range for positions and the division term\n",
        "        positions = tf.range(num_patches, dtype=tf.float32)[:, tf.newaxis]  # Shape: [num_patches, 1]\n",
        "        div_term = tf.exp(tf.range(0, embed_dim, 2, dtype=tf.float32) * -(tf.math.log(10000.0) / embed_dim))\n",
        "\n",
        "        # Compute sine and cosine for even and odd indices\n",
        "        even_indices = tf.sin(positions * div_term)\n",
        "        odd_indices = tf.cos(positions * div_term)\n",
        "\n",
        "        # Combine even and odd indices\n",
        "        pos_encoding = tf.concat([even_indices, odd_indices], axis=1)\n",
        "\n",
        "        return pos_encoding[:, :embed_dim]  # Ensure the shape matches [num_patches, embed_dim]\n",
        "\n",
        "    def call(self, x):\n",
        "        return x + self.pos_encoding\n"
      ],
      "metadata": {
        "id": "UqtyAgtmQpIQ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderBlock(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout_rate=0.1):\n",
        "        super(TransformerEncoderBlock, self).__init__()\n",
        "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation='relu'),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(dropout_rate)\n",
        "        self.dropout2 = Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n"
      ],
      "metadata": {
        "id": "2XenNMbgQqq6"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vit_model(input_shape, patch_size, embed_dim, num_heads, ff_dim, num_layers, num_classes):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    patches = PatchEmbedding(patch_size, embed_dim)(inputs)\n",
        "    num_patches = (input_shape[0] // patch_size) * (input_shape[1] // patch_size)\n",
        "    positions = PositionalEncoding(num_patches, embed_dim)(patches)\n",
        "    x = positions\n",
        "\n",
        "    for _ in range(num_layers):\n",
        "        x = TransformerEncoderBlock(embed_dim, num_heads, ff_dim)(x)  # No need to pass training\n",
        "\n",
        "    x = LayerNormalization(epsilon=1e-6)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(ff_dim, activation='relu')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n"
      ],
      "metadata": {
        "id": "0DZ-m49yQsO_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7cf-p9EgQt3_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype(\"int32\") / 255.0\n",
        "x_test = x_test.astype(\"int32\") / 255.0\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n"
      ],
      "metadata": {
        "id": "5jNEcKc_RCTB"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_model = create_vit_model(\n",
        "    input_shape=(32, 32, 3),\n",
        "    patch_size=4,\n",
        "    embed_dim=64,\n",
        "    num_heads=4,\n",
        "    ff_dim=128,\n",
        "    num_layers=8,\n",
        "    num_classes=10\n",
        ")"
      ],
      "metadata": {
        "id": "u2Jo62nFS8xq"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "4AjInoEsS9eK"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = vit_model.fit(x_train, y_train, batch_size=64, epochs=100, validation_split=0.2, verbose=1)\n"
      ],
      "metadata": {
        "id": "SPxWvvO7Va0g"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_model.save(\"./vit.keras\")"
      ],
      "metadata": {
        "id": "FsDctDL-VmGp"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=vit_model"
      ],
      "metadata": {
        "id": "5hIvNuc0fIXM"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Load CIFAR-10 Dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Function to convert images into byte vectors\n",
        "def images_to_byte_vectors(images):\n",
        "    # Flatten each image and cast to uint8 (0-255)\n",
        "    byte_vectors = images.reshape(images.shape[0], -1).astype(np.uint8)\n",
        "    return byte_vectors\n",
        "\n",
        "# Convert train and test images to byte vectors\n",
        "x_train_bytes = images_to_byte_vectors(x_train)\n",
        "x_test_bytes = images_to_byte_vectors(x_test)\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Debug: Check shapes\n",
        "print(f\"x_train_bytes shape: {x_train_bytes.shape}\")  # Expected: (50000, 3072)\n",
        "print(f\"x_test_bytes shape: {x_test_bytes.shape}\")    # Expected: (10000, 3072)\n"
      ],
      "metadata": {
        "id": "P115UHtPfyOW",
        "outputId": "afcbab67-34cf-42d0-9e7d-5890f08d7c14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train_bytes shape: (50000, 3072)\n",
            "x_test_bytes shape: (10000, 3072)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, Dense, Conv1D, LayerNormalization, Dropout, GlobalAveragePooling1D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "qNxs4zmZliHX"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "class ByteEmbedding(Layer):\n",
        "    def __init__(self, embed_dim):\n",
        "        super(ByteEmbedding, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.embedding_weights = tf.Variable(\n",
        "            initial_value=tf.random.normal([256, embed_dim], stddev=0.02),\n",
        "            trainable=True,\n",
        "            name=\"byte_embedding_weights\"\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Lookup the embeddings for the input byte indices\n",
        "        embeddings = tf.gather(self.embedding_weights, inputs)\n",
        "        return embeddings\n"
      ],
      "metadata": {
        "id": "8O5p0ih-f5JF"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ByteFormer(Model):\n",
        "    def __init__(self, num_patches, embed_dim, num_heads, ff_dim, num_blocks, kernel_size, stride, dropout_rate=0.1):\n",
        "        super(ByteFormer, self).__init__()\n",
        "\n",
        "        self.byte_embedding = ByteEmbedding(embed_dim)  # Byte embedding layer\n",
        "        self.conv1d = Conv1D(filters=embed_dim, kernel_size=kernel_size, strides=stride, padding=\"valid\", activation=\"relu\")\n",
        "        self.pos_encoding = PositionalEncoding(num_patches, embed_dim)  # Positional Encoding\n",
        "        self.transformer_blocks = [TransformerEncoderBlock(embed_dim, num_heads, ff_dim, dropout_rate) for _ in range(num_blocks)]\n",
        "        self.pooling = GlobalAveragePooling1D()  # Pooling after the transformer blocks\n",
        "        self.classifier = Dense(10, activation='softmax')  # Final classifier layer (CIFAR-10 has 10 classes)\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        # Step 1: Byte embedding\n",
        "        x = self.byte_embedding(x)\n",
        "\n",
        "        # Step 2: Strided convolution to reduce sequence length\n",
        "        x = self.conv1d(x)\n",
        "\n",
        "        # Step 3: Add positional encoding\n",
        "        x = self.pos_encoding(x)\n",
        "\n",
        "        # Step 4: Pass through transformer encoder blocks\n",
        "        for block in self.transformer_blocks:\n",
        "            x = block(x, training=training)\n",
        "\n",
        "        # Step 5: Global Average Pooling\n",
        "        x = self.pooling(x)\n",
        "\n",
        "        # Step 6: Final classification layer\n",
        "        return self.classifier(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "f-ACdy1OgQs6"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Parameters\n",
        "sequence_length = 1024  # Input sequence length before convolution\n",
        "embed_dim = 128         # Embedding dimension\n",
        "num_heads = 8           # Number of attention heads\n",
        "ff_dim = 512            # Feed-forward dimension\n",
        "num_blocks = 4          # Number of transformer encoder blocks\n",
        "dropout_rate = 0.1      # Dropout rate for regularization\n",
        "kernel_size = 3         # Kernel size for Conv1D\n",
        "stride = 2              # Stride for Conv1D\n",
        "\n",
        "# Adjust number of patches after convolution\n",
        "num_patches = (sequence_length - kernel_size) // stride + 1\n",
        "\n",
        "# Instantiate the model\n",
        "model = ByteFormer(num_patches=num_patches, embed_dim=embed_dim, num_heads=num_heads,\n",
        "                   ff_dim=ff_dim, num_blocks=num_blocks, kernel_size=kernel_size, stride=stride,\n",
        "                   dropout_rate=dropout_rate)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "QYmm8iUplJO4",
        "outputId": "a9337a39-e8e0-42d5-897f-e95fd27ec226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"byte_former_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"byte_former_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ byte_embedding_8 (\u001b[38;5;33mByteEmbedding\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ positional_encoding_8                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mPositionalEncoding\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder_block_22         │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mTransformerEncoderBlock\u001b[0m)            │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder_block_23         │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mTransformerEncoderBlock\u001b[0m)            │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder_block_24         │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mTransformerEncoderBlock\u001b[0m)            │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder_block_25         │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mTransformerEncoderBlock\u001b[0m)            │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d_2           │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_61 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ byte_embedding_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ByteEmbedding</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ positional_encoding_8                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEncoding</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder_block_22         │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoderBlock</span>)            │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder_block_23         │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoderBlock</span>)            │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder_block_24         │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoderBlock</span>)            │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder_block_25         │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoderBlock</span>)            │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d_2           │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fQXjJXPoldFY",
        "outputId": "711969ec-c688-477f-a69a-f3d33e22afbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'ByteEmbedding' object has no attribute 'compile'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-d621048fe83f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel11\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mByteEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'ByteEmbedding' object has no attribute 'compile'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "class ByteEmbedding(Model):\n",
        "    def __init__(self, embed_dim):\n",
        "        super(ByteEmbedding, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.byte_embedding = tf.keras.layers.Embedding(input_dim=256, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        embeddings = self.byte_embedding(inputs)\n",
        "        return embeddings\n"
      ],
      "metadata": {
        "id": "I55nrAPDlrWA"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model11=ByteEmbedding(embed_dim)\n",
        "model11.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "e8bSJ46enp3X"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model11.summary()"
      ],
      "metadata": {
        "id": "Rq96cRG4nrQw",
        "outputId": "ccffe1ef-a642-4af4-8796-a8037f9c2d7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"byte_embedding_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"byte_embedding_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m6Q0216YntKL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}